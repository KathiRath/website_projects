% $Header: /cvsroot/latex-beamer/latex-beamer/solutions/conference-talks/conference-ornate-20min.en.tex,v 1.7 2007/01/28 20:48:23 tantau Exp $

\documentclass[10pt]{beamer}

\mode<beamer>
{
  \usetheme{default}
  \usecolortheme[rgb={0,0,0.8}]{structure}
  %\setbeamercolor{normal text}{bg=blue!50}
  %\setbeamercolor{normal text}{fg=blue!50}
  % or ...

  %\setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}


\usepackage[english]{babel}
% or whatever

%\usepackage[latin1]{inputenc}
% or whatever

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

%\usepackage{newcent}
%\usefonttheme{structuresmallcapsserif}

\usepackage{amssymb,latexsym,amsmath}
\usepackage{amsthm}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\usepackage{mathtools}
\input xy 
\xyoption{all}
\usepackage[latin1]{inputenc}
\usepackage{color}
\usepackage{tikz}


\title[Gaussian Process for Time Series Analysis] % (optional, use only with long paper titles)
{Gaussian Process for Time Series Analysis}

%\subtitle

\author[Dr. Juan Orduz] % (optional, use only with lots of authors)
{Dr. Juan Orduz}
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[PyData Berlin 2018] % (optional, but mostly needed)
{

}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date[ PyData Berlin 2018] % (optional, should be abbreviation of conference name)
{ PyData Berlin 2019}
% - Either use conference name or its abbreviation.
% - Not really informative to the audience, more for people (including
%   yourself) who are reading the slides online

\subject{data science}
% This is only inserted into the PDF information catalog. Can be left
% out.



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

\pgfdeclareimage[height=0.7cm]{university-logo}{images/logo.png}
\logo{\pgfuseimage{university-logo}}

% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command:

%\beamerdefaultoverlayspecification{<+->}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}

%\begin{frame}{Contenido}
%\tableofcontents
%\end{frame}

\begin{frame}{Overview}
\tableofcontents
\end{frame}

\section{Introduction}

\begin{frame}{Multivariate Normal Distribution}
$X = (X_1, \cdots, X_d)$ has a{ \bf multivariate normal distribution} if every linear combination is normally distributed. In this case it has density of the form

$$
p(x|m,K_0) =\frac{1}{\sqrt{(2\pi)^{d}|K_0|}}\exp\left(-\frac{1}{2}(x - m)^T K_0^{-1}(x - m)\right)
$$
%(2\pi)^{−d/2}|K_0|^{−1/2}\exp\left(-\frac{1}{2}(x−m)^T {K_0}^{-1}(x−m)\right)

where $m \in \mathbb{R}^d$ is the {\bf mean vector} and  $K_0 \in M_d(\mathbb{R})$ is the (symmetric, positive definite) {\bf covariance matrix}.

\begin{center}
\begin{figure}
\includegraphics[scale=0.15]{images/multinormal_density.png} 
\includegraphics[scale=0.15]{images/no_multinormal_density.png} 
\caption{Left: Multivariate Normal Distribution, Right: Non-Multivariate Normal Distribution}
\end{figure}
\end{center}
\end{frame}

\section{Regularized Bayesian Linear Regression}

\begin{frame}{Regularized Bayesian Linear Regression}
Let $x_1, \cdots, x_n \in \mathbb{R}^d$ and $y_1, \cdots, y_n$ be a set of observations (data). We want to fit the linear model 
$$
f(x) = x^T b \quad \text{and} \quad y = f(x) + \varepsilon, \quad \text{with} \quad \varepsilon \sim N(0, \sigma_n^2)
$$
where $b \in \mathbb{R}^d$ denotes the parameter vector. Let $X \in M_{d \times n}$ be denote the observation matrix. 
\begin{center}
\begin{figure}
\includegraphics[scale=0.15]{images/lin_raw_data.png} 
\end{figure}
\end{center}
We want to compute $p(b|X, y)$ using the Bayes theorem 
$$
p(b|X, y) = \frac{p(y|X, b) p(b)}{p(y|X) } \propto \text{likelihood} \times \text{prior}
$$
\end{frame}


\begin{frame}{Prior Distribution}
\begin{itemize}
\item Likelihood
\begin{align*}
p(y|X, b) 
= \prod_{i=1}^{n}p(y_i|x_i, b) 
%=& \frac{1}{(2\pi \sigma_n^2)^{n/2}} \exp\left(-\frac{1}{2\sigma_n^2}||y - X^T b||^2\right) \\
= N(X^T b, \sigma_n^2 I)
\end{align*}

\item Prior 
$$
b \sim N(0, \Sigma_p), \quad  \Sigma_p \in M_{d}(\mathbb{R})
$$

\begin{center}
\begin{figure}
\includegraphics[scale=0.2]{images/lin_join_prior.png} 
\caption{Prior Distribution}
\end{figure}
\end{center}
\end{itemize}
\end{frame}


\begin{frame}{Posterior Distribution}
\begin{itemize}
\item Posterior 
$$
p(b|y, X) = N\left(\bar{b}=\frac{1}{\sigma_n^2}A^{-1}Xy, A^{-1}\right)
$$
where $A=\sigma_{n}^{-2}XX^T + \Sigma_p^{-1}$
\begin{center}
\begin{figure}
\includegraphics[scale=0.14]{images/lin_posterior_pymc3.png} 
\includegraphics[scale=0.14]{images/lin_join_posterior.png} 
\caption{Posterior Distribution}
\end{figure}
\end{center}
\end{itemize}
\end{frame}


\begin{frame}{Predictive Distribution}
\begin{align*}
p(f_*|x_*, X, y) 
=& \int p(f_*|x_*, b)p(b|X, y)db \\
=& N\left(\frac{1}{\sigma_n^2}x_*^T A^{-1}Xy, x_*^T A^{-1}x_*\right)
\end{align*}

\begin{center}
\begin{figure}
\includegraphics[scale=0.18]{images/lin_prediction.png} 
\caption{Left: Join Posterior Distribution, Right: Prediction + Confidence Interval}
\end{figure}
\end{center}
\end{frame}

\begin{frame}{References}{Slides and notebook available at juanitorduz.github.io}
\bibliographystyle{alpha}
\bibliography{references} 
\end{frame}

\section{The Kernel Trick}

\section{Gaussian Process Regression}

\section{Parameter Estimation}

\section{The Kernel Space}

\section{Time Series}

\end{document}





























